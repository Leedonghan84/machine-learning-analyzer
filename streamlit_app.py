# app.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import matplotlib
import io
import os
import re
import openai

from openpyxl import Workbook
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# ğŸ” OpenAI API í‚¤ ì„¤ì •
openai.api_key = "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"

# í•œê¸€ í°íŠ¸ ì„¤ì •
font_path = "./NanumGothic.ttf"
if os.path.exists(font_path):
    fm.fontManager.addfont(font_path)
    font_name = fm.FontProperties(fname=font_path).get_name()
    plt.rcParams['font.family'] = font_name
    matplotlib.rcParams['font.family'] = font_name
else:
    matplotlib.rcParams['font.family'] = ['Malgun Gothic', 'AppleGothic', 'Arial']
matplotlib.rcParams['axes.unicode_minus'] = False

# ğŸ§ª ë©”ì¸ ì†Œê°œ í˜ì´ì§€
st.title("âœˆï¸ ë¹„í–‰ê¸° ì‹¤í—˜ ë°ì´í„° ë¶„ì„ê¸°")
st.markdown("""
**ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ ì‹¤í—˜ ë°ì´í„° ë¶„ì„ ì•±ì…ë‹ˆë‹¤.**

- ì™¼ìª½ ë©”ë‰´ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ì„¤ëª…ê³¼ ì•Œê³ ë¦¬ì¦˜ì„ ì´í•´í•  ìˆ˜ ìˆì–´ìš”.
- ì•„ë˜ì—ì„œ ì‹¤í—˜ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš” âœ¨
""")

# ğŸ“Œ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— ë¨¸ì‹ ëŸ¬ë‹ ì„¤ëª…
st.sidebar.title("ğŸ“˜ ë¨¸ì‹ ëŸ¬ë‹ì´ë€?")
st.sidebar.markdown("""
ë¨¸ì‹ ëŸ¬ë‹ì€ ì»´í“¨í„°ê°€ **ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ**í•˜ê³  **ì˜ˆì¸¡ì„ ìˆ˜í–‰**í•˜ëŠ” ê¸°ìˆ ì´ì—ìš”.

- ì˜ˆ) ê³ ë¦¬ í¬ê¸°, ë¬´ê²Œ, íšŒì „ìˆ˜ ë“±ì„ í†µí•´ ë¹„í–‰ ì„±ëŠ¥ì„ ì˜ˆì¸¡í•´ìš”.
- ìš°ë¦¬ì˜ ì‹¤í—˜ ë°ì´í„°ë„ ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆì–´ìš”!

â¡ï¸ ì•„ë˜ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³ , ì˜ˆì¸¡ ëª¨ë¸ì„ ì„¤ì •í•´ë³´ì„¸ìš”!
""")

# AI ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_chat_response(prompt):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}"

# AI ë„ìš°ë¯¸ ì˜ì—­
with st.expander("ğŸ¤– AIì—ê²Œ ì§ˆë¬¸í•˜ê¸° (ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨ ë„ìš°ë¯¸)"):
    user_prompt = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”? ì˜ˆ: 'ëœë¤í¬ë ˆìŠ¤íŠ¸ê°€ ë­”ê°€ìš”?'", key="ai_chat")
    if user_prompt:
        with st.spinner("GPTê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤..."):
            answer = get_chat_response(user_prompt)
            st.markdown(f"ğŸ“ ë‹µë³€: {answer}")

# ğŸ”½ ì´í•˜ ê¸°ì¡´ ì—…ë¡œë“œ ë° ë¶„ì„ ì½”ë“œ ì´ì–´ì„œ ì‘ì„±ë¨...
